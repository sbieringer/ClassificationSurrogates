{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the output distirbutions of different Generative Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import normflows as nf\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from jet_dataset import JetDataset\n",
    "from script_jets import DDPM, SimpleCondFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model from ./data/NF_2_jets15/model_7499.pth\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "### Define the Normalizing Flow ###\n",
    "###################################\n",
    "\n",
    "# Define flows\n",
    "K = 10\n",
    "\n",
    "latent_size = 1\n",
    "hidden_units = 64\n",
    "hidden_layers = 2\n",
    "context_size = 16\n",
    "\n",
    "ep = 7499\n",
    "flow_dir = './data/NF_2_jets15/'\n",
    "\n",
    "flows = []\n",
    "for i in range(K):\n",
    "    flows += [nf.flows.AutoregressiveRationalQuadraticSpline(latent_size, hidden_layers, hidden_units, \n",
    "                                                             num_context_channels=context_size)]\n",
    "    flows += [nf.flows.LULinearPermute(latent_size)]\n",
    "\n",
    "# Set base distribution\n",
    "q0 = nf.distributions.DiagGaussian(1, trainable=False)\n",
    "    \n",
    "# Construct flow model\n",
    "flow = nf.ConditionalNormalizingFlow(q0, flows)\n",
    "\n",
    "# Move model on GPU if available\n",
    "flow = flow.to(device)\n",
    "flow.eval()\n",
    "\n",
    "flow.load_state_dict(torch.load(flow_dir + f\"model_{ep}.pth\"))\n",
    "print('loaded model from ' + flow_dir + f\"model_{ep}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "### Define the Normalizing Flow trained on reduced data ###\n",
    "###########################################################\n",
    "\n",
    "del_context_1 = ['label_top']\n",
    "\n",
    "# Define flows\n",
    "K = 10\n",
    "\n",
    "latent_size = 1\n",
    "hidden_units = 64\n",
    "hidden_layers = 2\n",
    "context_size = 16 - len(del_context_1)\n",
    "\n",
    "ep = 5000\n",
    "flow_dir = './data/NF_jets15_label_top/'\n",
    "\n",
    "flows = []\n",
    "for i in range(K):\n",
    "    flows += [nf.flows.AutoregressiveRationalQuadraticSpline(latent_size, hidden_layers, hidden_units, \n",
    "                                                             num_context_channels=context_size)]\n",
    "    flows += [nf.flows.LULinearPermute(latent_size)]\n",
    "\n",
    "# Set base distribution\n",
    "q0_1 = nf.distributions.DiagGaussian(1, trainable=False)\n",
    "    \n",
    "# Construct flow model\n",
    "flow_1 = nf.ConditionalNormalizingFlow(q0_1, flows)\n",
    "\n",
    "# Move model on GPU if available\n",
    "flow_1 = flow_1.to(device)\n",
    "flow_1.eval()\n",
    "\n",
    "flow_1.load_state_dict(torch.load(flow_dir + f\"model_{ep}.pth\"))\n",
    "print('loaded model from ' + flow_dir + f\"model_{ep}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "### Define the Normalizing Flow trained on only jet data ###\n",
    "############################################################\n",
    "\n",
    "del_context_2 = ['label_top', 'aux_genpart_eta', 'aux_genpart_phi', 'aux_genpart_pid', 'aux_genpart_pt',\t'aux_truth_match']\n",
    "\n",
    "# Define flows\n",
    "K = 10\n",
    "\n",
    "latent_size = 1\n",
    "hidden_units = 64\n",
    "hidden_layers = 2\n",
    "context_size = 16 - len(del_context_2)\n",
    "\n",
    "ep = 5000\n",
    "flow_dir = './data/NF_jets15_label_top_aux_genpart_eta_aux_genpart_phi_aux_genpart_pid_aux_genpart_pt_aux_truth_match/'\n",
    "\n",
    "flows = []\n",
    "for i in range(K):\n",
    "    flows += [nf.flows.AutoregressiveRationalQuadraticSpline(latent_size, hidden_layers, hidden_units, \n",
    "                                                             num_context_channels=context_size)]\n",
    "    flows += [nf.flows.LULinearPermute(latent_size)]\n",
    "\n",
    "# Set base distribution\n",
    "q0_2 = nf.distributions.DiagGaussian(1, trainable=False)\n",
    "    \n",
    "# Construct flow model\n",
    "flow_2 = nf.ConditionalNormalizingFlow(q0_2, flows)\n",
    "\n",
    "# Move model on GPU if available\n",
    "flow_2 = flow_2.to(device)\n",
    "flow_2.eval()\n",
    "\n",
    "flow_2.load_state_dict(torch.load(flow_dir + f\"model_{ep}.pth\"))\n",
    "print('loaded model from ' + flow_dir + f\"model_{ep}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "### Define the Diffusion Model ###\n",
    "##################################\n",
    "\n",
    "n_classes = 10 #have no effect\n",
    "n_feat = 256 # 128 ok, 256 better (but slower)\n",
    "n_T = 400 # probably total overkill\n",
    "\n",
    "ep = 59\n",
    "diff_dir = './data/diffusion_jets15_great/'\n",
    "\n",
    "nn_model_class = SimpleCondFF #ContextUnet\n",
    "\n",
    "ddpm = DDPM(nn_model=nn_model_class(in_channels=1, \n",
    "                                    n_feat=n_feat, \n",
    "                                    n_classes=n_classes), \n",
    "                                    betas=(1e-4, 0.02), n_T=n_T, device=device, drop_prob=0.1)\n",
    "ddpm.eval()\n",
    "\n",
    "ddpm.load_state_dict(torch.load(diff_dir + f\"model_{ep}.pth\"))\n",
    "print('loaded model from ' + diff_dir + f\"model_{ep}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "### Define the data ###\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "### get validation from the distribution tails ###\n",
    "##################################################\n",
    "\n",
    "dataset_val = JetDataset(\"./jet_data\", 'val')\n",
    "labels = np.array(dataset_val.data.keys())[2:]\n",
    "\n",
    "print(labels)\n",
    "\n",
    "plt.hist(dataset_val.features[:,1])\n",
    "plt.xlabel(labels[1])\n",
    "\n",
    "\n",
    "sort = np.argsort(dataset_val.features[:,1])\n",
    "for i in [200000, -100000, -10000]:\n",
    "    plt.vlines(dataset_val.features[sort[i],1], *plt.ylim(), color = 'red', label='target')\n",
    "    plt.text(dataset_val.features[sort[i],1], 350000, f'id = {sort[i]}')\n",
    "    print(dataset_val.features[sort[i],0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plot = 500\n",
    "n_stat_alea = 500\n",
    "\n",
    "\n",
    "for i in [5, 801, -100]:\n",
    "    dataset_train = JetDataset(\"./jet_data\", 'train')\n",
    "    conditions_train = np.array(dataset_train.features)\n",
    "\n",
    "    dataset_val = JetDataset(\"./jet_data\", 'val')\n",
    "    conditions = np.array(dataset_val.features)\n",
    "\n",
    "    dist_tmp = np.sqrt(np.sum(((conditions_train-conditions[i])**2), axis=1))\n",
    "    sort = np.argsort(dist_tmp)\n",
    "    x_data = torch.Tensor(dataset_train.target[sort[:n_plot]]*20)\n",
    "    _,b,_ = plt.hist(torch.sigmoid(x_data).numpy(), bins = 20, label = f'{n_plot} closest points')\n",
    "    del dataset_train, conditions_train\n",
    "\n",
    "    dataset_val = JetDataset(\"./jet_data\",'val')\n",
    "    conditions = torch.Tensor(dataset_val.features).to(device)\n",
    "    #bins = np.linspace(-20,20,40)\n",
    "\n",
    "    x_gen_flow, _ = flow.sample(1*n_stat_alea, context=conditions[i:i+1].repeat_interleave(n_stat_alea, dim=0))\n",
    "    x_gen_flow = torch.sigmoid(20*x_gen_flow)\n",
    "    _,b,_ = plt.hist(x_gen_flow.detach().cpu().numpy(), bins = b, histtype = 'step', label = 'Flow')\n",
    "    del x_gen_flow\n",
    "\n",
    "    x_gen_diff, _ = ddpm.sample(conditions[i:i+1].repeat_interleave(n_stat_alea, dim=0), device = device)\n",
    "    x_gen_diff = torch.sigmoid(20*x_gen_diff)\n",
    "    plt.hist(x_gen_diff.detach().cpu().numpy(), bins = b, histtype = 'step', label = 'Diffusion')\n",
    "    del x_gen_diff\n",
    "\n",
    "    # dataset_val = JetDataset(\"./jet_data\",'val', del_context=del_context_1)\n",
    "    # conditions = torch.Tensor(dataset_val.features).to(device)\n",
    "    # x_gen_flow, _ = flow_1.sample(1*n_stat_alea, context=conditions[i:i+1].repeat_interleave(n_stat_alea, dim=0))\n",
    "    # x_gen_flow *= 20\n",
    "    # _,b,_ = plt.hist(x_gen_flow.detach().cpu().numpy(), bins = b, histtype = 'step', label = 'Flow w/o truth')\n",
    "    # del x_gen_flow\n",
    "    \n",
    "    # dataset_val = JetDataset(\"./jet_data\",'val', del_context=del_context_2)\n",
    "    # conditions = torch.Tensor(dataset_val.features).to(device)\n",
    "    # x_gen_flow, _ = flow_2.sample(1*n_stat_alea, context=conditions[i:i+1].repeat_interleave(n_stat_alea, dim=0))\n",
    "    # x_gen_flow *= 20\n",
    "    # _,b,_ = plt.hist(x_gen_flow.detach().cpu().numpy(), bins = b, histtype = 'step', label = 'Flow only jet')\n",
    "    # del x_gen_flow\n",
    "\n",
    "    x_target = torch.Tensor(dataset_val.target[i:i+1]*20)\n",
    "    plt.vlines(torch.sigmoid(x_target).numpy(), *plt.ylim(), color = 'red', label='target')\n",
    "    del dataset_val\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'./out_{i}.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot over input bins\n",
    "\n",
    "n_bins = 5\n",
    "dataset_train = JetDataset(\"./jet_data\",'train')\n",
    "labels = np.array(dataset_train.data.keys())[2:]\n",
    "\n",
    "fig, ax = plt.subplots(dataset_train.features.shape[1], n_bins, figsize = (2*n_bins, 2*dataset_train.features.shape[1]), sharex=True, sharey=True)\n",
    "\n",
    "for i_f in range(dataset_train.features.shape[1]):\n",
    "    print(i_f, end = '\\r')\n",
    "    bins = np.linspace(dataset_train.features[:,i_f].min(), dataset_train.features[:,i_f].max(), n_bins+1)\n",
    "\n",
    "    for i_b in range(n_bins):\n",
    "\n",
    "        mask = np.bitwise_and(dataset_train.features[:,i_f]>=bins[i_b], dataset_train.features[:,i_f]<=bins[i_b+1])\n",
    "        ax[i_f,i_b].hist(dataset_train.target[mask]*20)\n",
    "        ax[i_f,0].set_ylabel(labels[i_f])\n",
    "        ax[i_f,i_b].set_title(f'[{bins[i_b]:3.2}, {bins[i_b+1]:3.2}]')\n",
    "\n",
    "fig.subplots_adjust(wspace=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesconda",
   "language": "python",
   "name": "bayesconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
